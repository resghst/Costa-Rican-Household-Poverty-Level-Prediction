{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'v2a1', 'hacdor', 'rooms', 'hacapo', 'v14a', 'refrig', 'v18q',\n",
       "       'v18q1', 'r4h1',\n",
       "       ...\n",
       "       'SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin',\n",
       "       'SQBovercrowding', 'SQBdependency', 'SQBmeaned', 'agesq', 'Target'],\n",
       "      dtype='object', length=143)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "# print(os.listdir('./data'))\n",
    "\n",
    "tf_train = pd.read_csv('./data/train.csv')\n",
    "tf_test = pd.read_csv('./data/test.csv')\n",
    "tf_train.head()\n",
    "tf_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bashline = 10*'-'\n",
    "def eda(data):\n",
    "    bashline = 10*'-'\n",
    "    # print(bashline,\"Top-5- Record\",bashline)\n",
    "    # print(data.head(5))\n",
    "    print(bashline,\"Information\",bashline)\n",
    "    print(data.info())\n",
    "    print(bashline,\"Data Types\",bashline)\n",
    "    print(data.dtypes)\n",
    "    print(bashline,\"Missing value\",bashline)\n",
    "    print(data.isnull().sum())\n",
    "    print(bashline,\"Null value\",bashline)\n",
    "    print(data.isna().sum())\n",
    "    print(bashline,\"Shape of Data\",bashline)\n",
    "    print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train = tf_train[tf_train['v2a1']!=0]\n",
    "tf_train = tf_train[tf_train['v2a1']<=900000]\n",
    "tf_train['v2a1'] = np.log(tf_train['v2a1'])\n",
    "\n",
    "tf_train = tf_train[tf_train['rooms']>=3]\n",
    "tf_train = tf_train[tf_train['rooms']<=7]\n",
    "\n",
    "tf_train = tf_train[tf_train['v18q1']<3]\n",
    "tf_train['v18q1'] = np.log(tf_train['v18q1'])\n",
    "tf_test['v18q1'] = np.log(tf_test['v18q1'])\n",
    "\n",
    "tf_train = tf_train[tf_train['r4h1']<2]\n",
    "\n",
    "tf_train = tf_train[tf_train['r4h2']>0]\n",
    "tf_train = tf_train[tf_train['r4h2']<3]\n",
    "\n",
    "tf_train = tf_train[tf_train['r4h3']<3]\n",
    "\n",
    "tf_train = tf_train[tf_train['r4m1']!=2]\n",
    "\n",
    "tf_train = tf_train[tf_train['r4m2']!=0]\n",
    "tf_train = tf_train[tf_train['r4m2']!=3]\n",
    "\n",
    "tf_train = tf_train[tf_train['r4m3']!=3]\n",
    "\n",
    "tf_train = tf_train[tf_train['r4t1']!=2]\n",
    "\n",
    "tf_train = tf_train[tf_train['r4t2']!=4]\n",
    "\n",
    "tf_train['r4t3'] = np.log(tf_train['r4t3'])\n",
    "tf_test['r4t3'] = np.log(tf_test['r4t3'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "tf_train[\"v2a1\"] = tf_train[\"v2a1\"].interpolate().fillna(0)\n",
    "tf_train[\"v18q1\"] = tf_train[\"v18q1\"].interpolate().fillna(0)\n",
    "print(type(tf_train))\n",
    "tf_train = tf_train.drop(['rez_esc'],axis=1)\n",
    "tf_train = tf_train.dropna()\n",
    "for i in tf_train.columns:\n",
    "    if(tf_train[i].isnull().sum()!=0): print(i,'\\t',tf_train[i].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "tf_test[\"v2a1\"] = tf_test[\"v2a1\"].interpolate().fillna(0)\n",
    "tf_test[\"v18q1\"] = tf_test[\"v18q1\"].interpolate().fillna(0)\n",
    "print(type(tf_test))\n",
    "tf_test = tf_test.drop(['rez_esc'],axis=1)\n",
    "tf_test = tf_test.fillna(0)\n",
    "for i in tf_test.columns:\n",
    "    if(tf_test[i].isnull().sum()!=0): print(i,'\\t',tf_test[i].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf_train.select_dtypes(include=[np.number]).interpolate().fillna(0)\n",
    "testdata = tf_test.select_dtypes(include=[np.number]).interpolate().fillna(0)\n",
    "y = tf_train.Target\n",
    "X = data.drop(['Target'], axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=88, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMeans Classifier  \n",
    "def KMeans_classifier(X_train, y_train):  \n",
    "    from sklearn.cluster import KMeans\n",
    "    return KMeans().fit(X_train,y_train)  \n",
    "\n",
    "# Multinomial Naive Bayes Classifier  \n",
    "def naive_bayes_classifier(X_train, y_train):  \n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    return MultinomialNB(alpha=0.01).fit(X_train, y_train)    \n",
    "\n",
    "# KNN Classifier  \n",
    "def knn_classifier(X_train, y_train):  \n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    return KNeighborsClassifier().fit(X_train, y_train)   \n",
    "\n",
    "# Logistic Regression Classifier  \n",
    "def logistic_regression_classifier(X_train, y_train):  \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    return LogisticRegression(penalty='l2').fit(X_train, y_train)    \n",
    "\n",
    "# Random Forest Classifier  \n",
    "def random_forest_classifier(X_train, y_train):  \n",
    "    from sklearn.ensemble import RandomForestClassifier \n",
    "    return RandomForestClassifier(n_estimators=8).fit(X_train, y_train)   \n",
    "\n",
    "# Decision Tree Classifier  \n",
    "def decision_tree_classifier(X_train, y_train):  \n",
    "    from sklearn import tree  \n",
    "    return tree.DecisionTreeClassifier().fit(X_train, y_train)   \n",
    "\n",
    "# GBDT(Gradient Boosting Decision Tree) Classifier  \n",
    "def gradient_boosting_classifier(X_train, y_train):  \n",
    "    from sklearn.ensemble import GradientBoostingClassifier  \n",
    "    return GradientBoostingClassifier(n_estimators=200).fit(X_train, y_train)  \n",
    "\n",
    "# SVM Classifier  \n",
    "def svm_classifier(X_train, y_train):  \n",
    "    from sklearn.svm import SVC\n",
    "    return SVC(kernel='rbf', probability=True).fit(X_train, y_train)   \n",
    "  \n",
    "#score test\n",
    "def score_test(y_test, predictions):\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.metrics import f1_score\n",
    "    print ('accuracy_score is: \\t {0:.6f}'.format(accuracy_score(y_test, predictions) ))\n",
    "    print ('RMSE is: \\t\\t {0:.6f}'.format(mean_squared_error(y_test, predictions) ))\n",
    "    print ('f1_score is: \\t\\t {0:.6f}'.format(f1_score(y_test, predictions, average='macro') ))\n",
    "\n",
    "train_model = {\n",
    "    'NB': naive_bayes_classifier(X_train, y_train),\n",
    "    'KNN': knn_classifier(X_train, y_train),\n",
    "    'LR': logistic_regression_classifier(X_train, y_train),\n",
    "    'RF': random_forest_classifier(X_train, y_train),\n",
    "    'DT': decision_tree_classifier(X_train, y_train),\n",
    "    'GBDT': gradient_boosting_classifier(X_train, y_train),\n",
    "    'SVM': svm_classifier(X_train, y_train)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t NB \t\t score\n",
      "accuracy_score is: \t 0.796\n",
      "RMSE is: \t\t 0.816\n",
      "f1_score is: \t\t 0.292\n",
      "\n",
      "\t KNN \t\t score\n",
      "accuracy_score is: \t 0.939\n",
      "RMSE is: \t\t 0.184\n",
      "f1_score is: \t\t 0.323\n",
      "\n",
      "\t LR \t\t score\n",
      "accuracy_score is: \t 0.959\n",
      "RMSE is: \t\t 0.163\n",
      "f1_score is: \t\t 0.660\n",
      "\n",
      "\t RF \t\t score\n",
      "accuracy_score is: \t 0.959\n",
      "RMSE is: \t\t 0.163\n",
      "f1_score is: \t\t 0.660\n",
      "\n",
      "\t DT \t\t score\n",
      "accuracy_score is: \t 0.959\n",
      "RMSE is: \t\t 0.163\n",
      "f1_score is: \t\t 0.660\n",
      "\n",
      "\t GBDT \t\t score\n",
      "accuracy_score is: \t 0.959\n",
      "RMSE is: \t\t 0.163\n",
      "f1_score is: \t\t 0.660\n",
      "\n",
      "\t SVM \t\t score\n",
      "accuracy_score is: \t 0.939\n",
      "RMSE is: \t\t 0.184\n",
      "f1_score is: \t\t 0.323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HANK\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\HANK\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\HANK\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\HANK\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\HANK\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\HANK\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\HANK\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\HANK\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in train_model:\n",
    "    print('\\n\\t',i,'\\t\\t score')\n",
    "    model = train_model[i]\n",
    "    predictions = model.predict(X_test)\n",
    "    score_test(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'finialpredictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-a4bdaea7b764>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msubmission\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msubmission\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mId\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msubmission\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Target'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinialpredictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0msubmission\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'output.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'finialpredictions' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['Id'] = tf_test.Id\n",
    "submission['Target'] = finialpredictions\n",
    "submission.to_csv('output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
